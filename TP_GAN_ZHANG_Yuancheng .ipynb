{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "TP_GAN_ZHANG_Yuancheng.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIS8sRlra9dV"
      },
      "source": [
        "# [UE Biometrics] TP GAN\n",
        "ZHANG Yuancheng\n",
        "3704091"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT7qVfrca9dg"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import os \n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w94mrtr-a9dh"
      },
      "source": [
        "class ConvGAN():\n",
        "    def __init__(self):\n",
        "        \n",
        "        # shape of input images (for MNIST, 28 x 28)\n",
        "        self.img_rows = 28\n",
        "        self.img_cols = 28\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        \n",
        "        # distribute into 10 classes\n",
        "        #self.num_classes = 10\n",
        "        \n",
        "        # dimension of random latent (input for generator)\n",
        "        self.latent_dim = 32\n",
        "        \n",
        "        # adam optimizer\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "        \n",
        "        # discriminator model\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss=['binary_crossentropy'], optimizer=optimizer, metrics=['accuracy'])\n",
        "        \n",
        "        # generator model\n",
        "        self.generator = self.build_generator()\n",
        "        \n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "        \n",
        "        # when training generator, stop training discriminator\n",
        "        self.discriminator.trainable = False\n",
        "        \n",
        "        # evaluate the generated image\n",
        "        valid = self.discriminator(img)\n",
        "        \n",
        "        # combine generator and discriminator\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        # a first dense layer which transforms the input of generator to dimension of 14*14*128\n",
        "        model.add(Dense(14 * 14 * 128, use_bias = False, input_shape=(self.latent_dim, )))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        # reshape\n",
        "        model.add(Reshape((14, 14, 128)))\n",
        "\n",
        "        # 14*14*128 -> 14*14*128\n",
        "        model.add(Conv2DTranspose(128, (5, 5), use_bias = False, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        \n",
        "        # 14*14*128 -> 14*14*256\n",
        "        model.add(Conv2DTranspose(256, (5, 5), use_bias = False, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        \n",
        "        # 14*14*256 -> 28*28*128\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2DTranspose(128, (5, 5), use_bias = False, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "        # 14*14*128 -> 28*28*1\n",
        "        model.add(Conv2DTranspose(self.channels, (5, 5), use_bias = False, padding=\"same\", activation=LeakyReLU(alpha=0.2)))\n",
        "\n",
        "        model.summary()\n",
        "        \n",
        "        # input: random numbers\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        # output: generated images\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        \n",
        "        model.add(Conv2D(256, (5, 5), input_shape=self.img_shape))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        \n",
        "        \n",
        "        model.add(Conv2D(128, (5, 5)))\n",
        "        #model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        \n",
        "        \n",
        "        #model.add(ZeroPadding2D(((0,1),(0,1))))\n",
        "        model.add(Conv2D(64, (5, 5)))\n",
        "        #model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        \n",
        "        #model.add(GlobalAveragePooling2D())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        # input: \n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, show_save_frequency=10):\n",
        "        # load mnist dataset\n",
        "        (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "        # normalization to [-1, 1]\n",
        "        X_train = X_train / 127.5 - 1.\n",
        "        X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        # shuffle\n",
        "        #train_datasets = tf.data.Dataset.from_tensor_slices(X_train)\n",
        "        #train_datasets = train_datasets.shuffle(X_train.shape[0]).batch(128)\n",
        "\n",
        "        # ground truths: valid or fake\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "                 \n",
        "            # ------------------------ #\n",
        "            #  train the discriminator #\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "            #print(imgs.shape)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            # train and compute loss\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ------------------------ #\n",
        "            #  train the generator  #\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "            \n",
        "            # show and save images for every 10 epochs\n",
        "            if epoch % show_save_frequency == 0:\n",
        "                self.show_and_save_imgs(epoch)\n",
        "\n",
        "    def show_and_save_imgs(self, epoch):\n",
        "        row, col = 2, 5\n",
        "        noise = np.random.normal(0, 1, (row * col, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(row, col)\n",
        "        cnt = 0\n",
        "        for i in range(row):\n",
        "            for j in range(col):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        #fig.savefig(\"images/mnist_%d.png\" % epoch)         \n",
        "        #plt.close()             # activate this part if you want to save the generated images"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DYhv312Qa9dj"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    #if not os.path.exists(\"./images\"):\n",
        "        #os.makedirs(\"./images\")       # activate this part if you want to save the generated images\n",
        "    convgan = ConvGAN()\n",
        "    convgan.train(epochs=300, batch_size=256, show_save_frequency=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}